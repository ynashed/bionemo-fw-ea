type: recipe
format_version: 1
maintainers: [dorotat]
logger: dllogger
labels:
  origin: bionemo
  workload_ref: ""
key_segments:
  domain: domain
  config_name: config
  warmup: warmup
  config_path: False
  default_overwrites: False
  extra_overwrites: False
launchers:
  type:slurm:
    ntasks_per_node: '{gpus}'
spec:
  build: bionemo
  scope: perf-train
  platforms: [linux/amd64]
  BIONEMO_HOME: "/workspace/bionemo"
  MODEL_PATH: "/workspace/bionemo/models"
  NGC_CLI_FORMAT_TYPE: ascii
  NGC_CLI_ORG: nvidian
  NGC_CLI_TEAM: clara-lifesciences
  config_path: "examples/tests/conf/"
  warmup: 0
  default_overwrites: "trainer.max_steps=100 ++exp_manager.create_wandb_logger=False ++exp_manager.create_tensorboard_logger=False ++exp_manager.exp_dir=/tmp/nemo_experiments/ ++exp_manager.create_checkpoint_callback=False ++exp_manager.resume_if_exists=False ++trainer.check_val_every_n_epoch=null"
  extra_overwrites: ""
  script: |-
    cd {BIONEMO_HOME}
    export NGC_CLI_ORG={NGC_CLI_ORG} 
    export NGC_CLI_TEAM={NGC_CLI_TEAM} 
    export NGC_CLI_FORMAT_TYPE={NGC_CLI_FORMAT_TYPE} 
    export MODEL_PATH={MODEL_PATH}
    if [ "$SLURM_LOCALID" = "0" ]; then
      source download_models.sh && download_bionemo_models;
      touch .download-finished;
    else
      until [ -f .download-finished ]; do
        sleep 5;
      done
    fi  
    python examples/{domain}/downstream/{variant}.py --config-path {BIONEMO_HOME}/{config_path} --config-name {config_name} \
    trainer.num_nodes={nodes} trainer.devices={gpus} trainer.precision={precision} model.micro_batch_size={batch_size} \
    {default_overwrites} {extra_overwrites} hydra.searchpath=[file://{BIONEMO_HOME}/examples/{domain}/{model}/conf] \
    ++create_dllogger_callbacks=True ++create_trainer_metric_callback=True \
    ++dllogger_callbacks_kwargs.use_existing_dllogger=True ++dllogger_callbacks_kwargs.warmup={warmup} \
    ++dllogger_callbacks_kwargs.json_file={dllogger_file} ++trainer_metric_callback_kwargs.log_path={assets_dir} ++logs_dir={logs_dir}
  time_limit: 3600
  artifacts: {}
  metrics:
    throughput_train:
      goal: maximize
      tags: [primary]
    latency_train_mean:
      goal: minimize
      tags: [secondary]
    train_loss:
      goal: minimize
      tags: [secondary]
products:
  - nodes: [1]
    gpus: [1, 8]
    precision: [16, 32, bf16]
    domain: [protein]
    variant: [downstream_flip]
    products:
      - model: [esm1nv]
        batch_size: [32]
        config_name: [esm1nv_encoder_finetune_test]
      - model: [prott5nv]
        batch_size: [32]
        config_name: [prott5nv_encoder_finetune_test]
