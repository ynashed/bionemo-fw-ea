type: recipe
format_version: 1
maintainers: [dorotat]
logger: dllogger
labels:
  origin: bionemo
  workload_ref: ""
key_segments:
  domain: domain
  config_name: config
  warmup: warmup
  config_path: False
  default_overwrites: False
  extra_overwrites: False
launchers:
  type:slurm:
    ntasks_per_node: '{gpus}'
  name:dgxa100_dracooci:
    mounts:
      /workspace/bionemo/models: /lustre/fsw/portfolios/convai/projects/convai_bionemo_training/jet/models
spec:
  build: bionemo
  scope: perf-infer
  platforms: [linux/amd64]
  BIONEMO_HOME: "/workspace/bionemo"
  MODEL_PATH: "/workspace/bionemo/models"
  NGC_CLI_FORMAT_TYPE: ascii
  NGC_CLI_ORG: nvidian
  NGC_CLI_TEAM: clara-lifesciences
  config_path: "examples/tests/conf/"
  script_path: "bionemo/model"
  default_overwrites: "++exp_manager.exp_dir=/tmp/nemo_experiments/"
  extra_overwrites: ""
  warmup: 0
  script: |-
    cd {BIONEMO_HOME}
    python {script_path}/{variant}.py --config-path {BIONEMO_HOME}/{config_path} --config-name {config_name} \
    trainer.num_nodes={nodes} trainer.devices={gpus} trainer.precision={precision} ++model.data.batch_size={batch_size} \
    {default_overwrites} {extra_overwrites}  \
    ++create_dllogger_callbacks=True ++dllogger_callbacks_kwargs.use_existing_dllogger=True \
    ++dllogger_callbacks_kwargs.warmup={warmup} \
    ++dllogger_callbacks_kwargs.json_file={dllogger_file} ++assets_dir={assets_dir} ++logs_dir={logs_dir}
  time_limit: 3600
  artifacts: {}
  metrics:
    throughput_train:
      goal: maximize
      tags: [primary]
    latency_train_mean:
      goal: minimize
      tags: [secondary]
    train_loss:
      goal: minimize
      tags: [secondary]
products:
  - nodes: [1]
    gpus: [8]
    precision: [32, bf16-mixed]
    variant: [infer]
    products:
      - domain: [molecule]
        model: [megamolbart]
        config_name: [megamolbart_infer]
        batch_size: [4]
        checkpoint_name: [megamolbart]
      - domain: [protein]
        products:
          - model: [esm1nv]
            config_name: [esm1nv_infer]
            batch_size: [4]
            checkpoint_name: [esm1nv]
          - model: [esm2nv]
            config_name: [esm2nv_infer]
            batch_size: [4]
            checkpoint_name: [esm2nv_650m]
          - model: [prott5nv]
            config_name: [prott5nv_infer]
            batch_size: [4]
            checkpoint_name: [prott5nv]
