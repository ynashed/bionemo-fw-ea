type: recipe
format_version: 1
maintainers: [dorotat]
logger: dllogger
labels:
  origin: bionemo
  workload_ref: ""
key_segments:
  domain: domain
  dwnstr_task: dwnstrtask
  config_name: config
  warmup: warmup
  config_path: False
  default_overwrites: False
  extra_overwrites: False
launchers:
  type:slurm:
    ntasks_per_node: '{gpus}'
spec:
  build: bionemo
  scope: perf-train
  platforms: [linux/amd64]
  BIONEMO_HOME: "/workspace/bionemo"
  MODEL_PATH: "/workspace/bionemo/models"
  NGC_CLI_FORMAT_TYPE: ascii
  NGC_CLI_ORG: nvidian
  NGC_CLI_TEAM: clara-lifesciences
  config_path: "examples/tests/conf/"
  warmup: 0
  default_overwrites: "++exp_manager.create_wandb_logger=False ++exp_manager.create_tensorboard_logger=False ++exp_manager.exp_dir=/tmp/nemo_experiments/ ++exp_manager.create_checkpoint_callback=False ++exp_manager.resume_if_exists=False"
  extra_overwrites: ""
  script: |-
    cd {BIONEMO_HOME}
    export NGC_CLI_ORG={NGC_CLI_ORG}
    export NGC_CLI_TEAM={NGC_CLI_TEAM}
    export NGC_CLI_FORMAT_TYPE={NGC_CLI_FORMAT_TYPE}
    if [ "$SLURM_LOCALID" = "0" ]; then
      if [ "{model}" = "megamolbart" ]; then
        python download_models.py {model} --download_dir {MODEL_PATH} --verbose;
      fi
      if [ "{model}" = "esm2nv" ]; then
        unzip examples/tests/test_data/uniref202104_esm2_qc_test200_val200.zip -d examples/tests/test_data/;
      fi
      touch .download-finished;
    else
      until [ -f .download-finished ]; do
        sleep 5;
      done
    fi
    python examples/{domain}/{model}/{variant}.py --config-path {BIONEMO_HOME}/{config_path} --config-name {config_name} \
    trainer.num_nodes={nodes} trainer.devices={gpus} trainer.precision={precision} model.micro_batch_size={batch_size} \
    ++model.dwnstr_task_validation.enabled={dwnstr_task} \
    {default_overwrites} {extra_overwrites} hydra.searchpath=[file://{BIONEMO_HOME}/examples/{domain}/{model}/conf] \
    ++create_dllogger_callbacks=True ++create_trainer_metric_callback=True \
    ++dllogger_callbacks_kwargs.use_existing_dllogger=True ++dllogger_callbacks_kwargs.warmup={warmup} \
    ++dllogger_callbacks_kwargs.json_file={dllogger_file} ++trainer_metric_callback_kwargs.log_path={assets_dir} ++logs_dir={logs_dir}
  time_limit: 3600
  artifacts: {}
  metrics:
    throughput_train:
      goal: maximize
      tags: [primary]
    latency_train_mean:
      goal: minimize
      tags: [secondary]
    train_loss:
      goal: minimize
      tags: [secondary]
products:
  - nodes: [1]
    gpus: [1, 8]
    precision: [16, 32, bf16]
    products:
      - domain: [molecule]
        model: [megamolbart]
        batch_size: [32]
        products:
          - variant: [pretrain]
            dwnstr_task: [False, True]
            config_name: [megamolbart_test]
          - variant: [downstream_retro]
            config_name: [megamolbart_downstream_retro_test]
            dwnstr_task: [False]
          - variant: [downstream_physchem]
            config_name: [megamolbart_physchem_test]
            dwnstr_task: [False]
            extra_overwrites: ["++trainer.check_val_every_n_epoch=null"]
      - domain: [protein]
        dwnstr_task: [False, True]
        products:
          - model: [esm1nv]
            batch_size: [32]
            variant: [pretrain]
            config_name: [esm1nv_test]
          - model: [esm2nv]
            batch_size: [2]
            variant: [pretrain]
            config_name: [esm2nv_8M_test]
          - model: [prott5nv]
            batch_size: [12]
            variant: [pretrain]
            config_name: [prott5nv_test]
