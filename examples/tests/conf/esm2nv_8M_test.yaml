defaults:
  - pretrain_esm2_8M

hydra:
  searchpath:
    - file:///workspace/bionemo/examples/protein/esm2nv/conf

trainer:
  devices: 1
  num_nodes: 1
  max_epochs: 1 # PTL default. In practice we don't usually train for more than 1 epoch.
  max_steps: 500 # consumed_samples = global_step * micro_batch_size * data_parallel_size * accumulate_grad_batches
  limit_val_batches: 10
  limit_test_batches: 1
  val_check_interval: 1.0
  check_val_every_n_epoch: 1


model:
  data:
    val_size: 200
    test_size: 200
    uf50_datapath: ${oc.env:PROJECT_MOUNT}/examples/tests/test_data/uniref202104_esm2_qc_test200_val200/uniref50_train_filt.fasta
    uf90_datapath: ${oc.env:PROJECT_MOUNT}/examples/tests/test_data/uniref202104_esm2_qc_test200_val200/ur90_ur50_sampler.fasta
    cluster_mapping_tsv: ${oc.env:PROJECT_MOUNT}/examples/tests/test_data/uniref202104_esm2_qc_test200_val200/mapping.tsv
    index_mapping_dir: ${oc.env:PROJECT_MOUNT}/examples/tests/test_data/uniref202104_esm2_qc_test200_val200
    dataset_path: ${oc.env:PROJECT_MOUNT}/examples/tests/test_data/uniref202104_esm2_qc_test200_val200/uf50
    uf90:
      uniref90_path: ${oc.env:PROJECT_MOUNT}/examples/tests/test_data/uniref202104_esm2_qc_test200_val200/uf90/

  dwnstr_task_validation:
    enabled: False
    dataset:
      emb_batch_size: 24
      batch_size: ${.emb_batch_size}
      num_epochs: 1
      task_name: downstream
      dataset_path: ${oc.env:PROJECT_MOUNT}/examples/tests/test_data/protein/downstream



exp_manager:
  exp_dir: /tmp/nemo_experiments/esm2nv_pretrain
  create_wandb_logger: False
  create_tensorboard_logger: False
  create_checkpoint_callback: False
  resume_if_exists: False
  wandb_logger_kwargs:
    offline: True