{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5accdbca",
   "metadata": {},
   "source": [
    "# Inference Sample for ESM2\n",
    "\n",
    "SPDX-FileCopyrightText: Copyright (c) <year> NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "SPDX-License-Identifier: LicenseRef-NvidiaProprietary\n",
    "\n",
    "NVIDIA CORPORATION, its affiliates and licensors retain all intellectual property and proprietary rights in and to this material, related documentation and any modifications thereto. Any use, reproduction, disclosure or distribution of this material and related documentation without an express license agreement from NVIDIA CORPORATION or its affiliates is strictly prohibited.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "- Linux OS\n",
    "- Pascal, Volta, Turing, or an NVIDIA Ampere architecture-based GPU.\n",
    "- NVIDIA Driver\n",
    "- Docker\n",
    "\n",
    "#### Import\n",
    "\n",
    "Components for inferencing are part of the BioNeMo ESM source code. This notebook demonstrates the use of these components.\n",
    "\n",
    "__`ESMInferenceWrapper`__ implements __`seq_to_embedding`__ function to obtain encoder embeddings for the input protein sequence in text format. \n",
    "\n",
    "\n",
    "To run this notebook, you should launch the gRPC client in your terminal beforehand. \n",
    "\n",
    "The following command is an example of launching the gRPC inference client using the esm2-650M checkpoints:\n",
    "\n",
    "```python3 -m bionemo.model.protein.esm1nv.grpc.service --model esm2nv_650M```\n",
    "\n",
    "Note that gRPC limits request size to 4MB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6147e128237998f3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f210ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "try:\n",
    "    BIONEMO_HOME: Path = Path(os.environ['BIONEMO_HOME']).absolute()\n",
    "except KeyError:\n",
    "    print(\"Must have BIONEMO_HOME set in the environment! See docs for instructions.\")\n",
    "    raise\n",
    "\n",
    "config_path = BIONEMO_HOME / \"examples\" / \"protein\" / \"esm2nv\" / \"conf\"\n",
    "print(f\"Using model configuration at: {config_path}\")\n",
    "assert config_path.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d25dcf",
   "metadata": {},
   "source": [
    "### Setup and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [\n",
    "    'MSLKRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL', \n",
    "    'MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3109c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bionemo.triton.utils import load_model_config\n",
    "\n",
    "cfg = load_model_config(config_path, config_name=\"infer.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bionemo.triton.utils import load_model_for_inference\n",
    "from bionemo.model.protein.esm1nv.infer import ESM1nvInference\n",
    "\n",
    "inferer = load_model_for_inference(cfg, interactive=True)\n",
    "\n",
    "print(f\"Loaded a {type(inferer)}\")\n",
    "assert isinstance(inferer, ESM1nvInference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33eb8d3",
   "metadata": {},
   "source": [
    "### Sequence to Hidden States\n",
    "\n",
    "__`seq_to_hiddens`__ queries the model to fetch the encoder hiddens states for the input protein sequence. `pad_mask` is returned with `hidden_states` and contains padding information  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde52a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, pad_masks = inferer.seq_to_hiddens(seqs)\n",
    "print(f\"{hidden_states.shape=}\")\n",
    "print(f\"{pad_masks.shape=}\")\n",
    "assert tuple(hidden_states.shape) == (2, 43, 1280)\n",
    "assert tuple(pad_masks.shape) == (2, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130b163",
   "metadata": {},
   "source": [
    "### Hidden States to Embedding\n",
    "\n",
    "__`hiddens_to_embedding`__ computes embedding vector by averaging `hidden_states` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96409cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = inferer.hiddens_to_embedding(hidden_states, pad_masks)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embeddings.shape) == (2, 1280)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f420f14",
   "metadata": {},
   "source": [
    "### Sequence to Embedding\n",
    "\n",
    "__`seq_to_embedding`__  queries the model to fetch the encoder hiddens states and computes embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = inferer.seq_to_embeddings(seqs)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embeddings.shape) == (2, 1280)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
