defaults:
  - embedding_preprocess

name: ScoreModel  # if data.all_atoms is True, use ScoreModelAA, or use ScoreModelCG for coarse grained model
do_embedding_preprocessing: False # prepares PDB files to ESM embeddings needed for training.
do_preprocessing: False # prepare the complex graphs needed for training as input.
do_training: True # set to false if data preprocessing steps must be completed
do_testing: False # set to true to run evaluation on test data after training, requires test_dataset section
seed: 42
cluster_type: None # set to 'BCP' if needed

restore_from_path: null # used when starting from a .nemo file
target: bionemo.model.molecule.diffdock.models.nemo_model.DiffdockTensorProductScoreModel  # path to model class to load
infer_target: bionemo.model.molecule.diffdock.infer.ScoreModelInference # path to inferende class to load

data:
  num_workers: 4
  pin_memory: False
  limit_complexes: 0
  all_atoms: False
  receptor_radius: 15
  c_alpha_max_neighbors: 24
  atom_radius: 5.0
  atom_max_neighbors: 8
  matching_popsize: 20
  matching_maxiter: 20
  max_lig_size: null
  remove_hs: True
  num_conformers: 1
  world_size: ${multiply:${trainer.devices}, ${trainer.num_nodes}}
  esm_embeddings_path: ${training_data.esm_embeddings_path}
  data_dir: ${training_data.protein_data_dir} # Folder containing original structures
  split_train: ${oc.env:BIONEMO_HOME}/data/splits/split_train # Path of file defining the split.
  split_val: ${oc.env:BIONEMO_HOME}/data/splits/split_val # Path of file defining the split
  split_test: ${oc.env:BIONEMO_HOME}/data/splits/split_test # Path of file defining the split
  cache_path: ${oc.env:BIONEMO_HOME}/data/data_cache # Folder from where to load/restore cached dataset
  chunk_size: 5 # Number of samples as a chunk given to each process to process each time when preparing the dataset in class ProteinLigandDockingDataset, default is 5

trainer:
  devices: 1
  num_nodes: 1
  precision: 32 # currently only single precision is supported
  accelerator: gpu # gpu or cpu
  max_epochs: 1000 # set to null when using max_steps instead with NeMo model
  max_steps: -1
  log_every_n_steps: 50 # number of iterations between logging
  val_check_interval: null # set to integer when using steps to determine frequency of validation, use fraction with epochs
  check_val_every_n_epoch: 1 # Perform a validation loop every after every N training epochs
  num_sanity_val_steps: 2 # set to 0 or small number to test validation before training
  limit_val_batches: 200 # number of batches in validation step, use fraction for fraction of data
  limit_test_batches: 0 # number of batches in test step, use fraction for fraction of data
  gradient_clip_val: 1.0
  logger: False # logger is provided by NeMo exp_manager
  enable_checkpointing: False # checkpointing is done by NeMo exp_manager
  replace_sampler_ddp: False # set to False if using custom sampler                                                                  >> Marta<>Pouria discussion
  reload_dataloaders_every_n_epochs: 100000 # Set to a non-negative integer to reload dataloaders every n epochs. Default: ``0``.
  accumulate_grad_batches: 1

model:
  name: ${name}
  esm_embeddings_path: ${data.esm_embeddings_path}
  seed: ${seed}
  # data parallelism
  # To avoid the OOM issue, use batch_sampler: SizeAwareBatchSampler,
  #      together with adjusting micro_batch_size, max_total_size, max_element_size, and num_batches(in each dataset config)
  # How to adjust and set proper values for these number:
  #                     sif getting info like "Only 99 out of 100 samples are used", increase max_total_size or num_batches slightly
  #                     if having OOM, reduce max_total_size
  #                     if OOM is from a batch with only one sample, set max_element_size to a finite number to skip these samples
  micro_batch_size: 16 # number of samples per batch, 
                      # if batch_sampler is SizeAwareBatchSampler, only used to estimate and set default value for num_batches
                      # if using other batch_sampler, this will be the exact mirco batch size
  global_batch_size: null # this will be set automatically by the `setup_trainer(cfg)`
  batch_sampler: SizeAwareBatchSampler # null, SizeAwareBatchSampler
  max_total_size: 70000.0 # only used for batch_sampler is SizeAwareBatchSampler, upper bound of memory usage, unit MiB
                          # as memory usage changes as diffusion step changes, so in the SizeAwareBatchSampler, 
                          # we use a upper bound for maximal memory usage when generating each batch of samples
                          # this can be slightly larger than model.estimate_memory_usage.maximal, 1.1 ~ 1.15 * model.estimate_memory_usage.maximal
                          # 42000 on A6000, 70000 on A100, 18000 on RTX3090
                          # if null, default to use 0.85 * total memory of cuda:0
  estimate_memory_usage:
    # estimated memory usage will be: total_memory = coeff_ligand_num_nodes * num_nodes(ligand) + coeff_ligand_num_edges * num_edges(ligand) + ... + bias
    # unit here is MiB
    # this is estimated from forward pass in training, so ${.maximal} is smaller than the GPU capacity
    # skip the batch in training if total_memory > maximal
    # these numbers are from linear regression, and only for this model configuration
    # num. of nodes and num. of edges have strong linear dependence, coeff = 0.0 doesn't means they don't contribute to memory usage
    coeff_ligand_num_nodes: 2.9
    coeff_ligand_num_edges: 0.0
    coeff_receptor_num_nodes: 0.0
    coeff_receptor_num_edges: 0.11
    coeff_num_cross_edges: 0.25
    bias: 435.0
    maximal: 60000.0 # skip the batch if estimated memory is lager than this number, unit MiB 
                     # in the forward call of the score model, forward diffusion is done, we can get an accurate estimation of memory usage
                     # so here we have a much tighter memory threshold, if memory is over maximal, most likely it will lead to crash due to OOM
                     # 37000 on A6000, 60000 on A100, 17000 on RTX3090
                     # if null, use 0.75 * total memory of cuda:0
    estimate_num_cross_edges: 
      # estimate the upper bound of the number of cross edges
      # the function is defined as 
      # scale * (  4.92 * graph['ligand', 'ligand'].num_edges 
      #          + 0.0118 * graph['receptor', 'receptor'].num_edges
      #          + 0.0401 * graph['ligand'].num_nodes * graph['receptor', 'receptor'].num_edges )
      scale: 1.03
      terms:
        - - 4.92
          - 'ligand_ligand'
        - - 0.0118
          - 'receptor_receptor'
        - - 0.0401
          - 'ligand'
          - 'receptor_receptor'
  resume_from_checkpoint: null # manually set the checkpoint file to load from
  tensor_model_parallel_size: 1
  pipeline_model_parallel_size: 1
  # model architecture
  confidence_mode: False # False: train score model; True: train confidence model
  num_conv_layers: 6
  max_radius: 5.0
  scale_by_sigma: True
  ns: 48
  nv: 10
  distance_embed_dim: 64
  cross_distance_embed_dim: 64
  no_batch_norm: False
  batch_norm_with_shift: True # batchnorm from e3nn uses only scaling (without shifting) for non-scalars (l>=1)
                               # this flag controls whether using shifting for scalars, default is True (like standard batchnorm)
                               # When do training with batch_norm_with_shift=false, in inference, we found with the shift in the
                               # batch norm makes the prediction more stable rather than go wildly and lead to nan values
  tensor_product:
    use_second_order_repr: False
    type: "e3nn" # choose from ["e3nn" (default), "marta"]
  cross_max_distance: 80.0
  dynamic_max_cross: True
  dropout: 0.1
  embedding_type: "sinusoidal"
  sigma_embed_dim: 64
  embedding_scale: 10000
  all_atoms: ${data.all_atoms}
  diffusion:
    tr_weight: 0.33
    rot_weight: 0.33
    tor_weight: 0.33
    tr_sigma_min: 0.1
    tr_sigma_max: 19
    rot_sigma_min: 0.03
    rot_sigma_max: 1.55
    tor_sigma_min: 0.0314 # 'Minimum sigma for torsional component'
    tor_sigma_max: 3.14 # 'Maximum sigma for torsional component'
    no_torsion: False # 'If set only rigid matching'
  # model-specific control
  test_sigma_intervals: False # Whether to log loss per noise interval
  val_denoising_inference_freq: 5 # Frequency of epochs for which to run expensive denoising inference on val data
  denoising_inference_steps: 20 # Number of denoising steps for inference on val
  num_denoising_inference_complexes: 500 # number of samples from validation dataset to run expensive denoising inference
  inference_earlystop_metric: 'valinf_rmsds_lt2' # valinf_rmsds_lt2: percentage of RMSD < 2 from denosing inference on validation dataset
  inference_earlystop_goal: 'max'
  find_unused_parameters: True # the model has certain parameters may not be used during training in some batches
                               # set to True so for multi-gpu training, if unused parameters are found, the gradient Reducer will only wait for unready parameters
                               # refer to https://pytorch.org/docs/stable/notes/ddp.html for more details.

  optim:
    name: fused_adam # fused optimizers used by model
    lr: 0.001 # max is scaled by scheduler
    betas:
      - 0.9
      - 0.999
    eps: 1e-8
    weight_decay: 0.01
    sched:
      name: ReduceLROnPlateau # plateau
      patience: 30
      monitor: ${model.inference_earlystop_metric} # key for ReduceLROnPlateau
      mode: ${model.inference_earlystop_goal}
      # d_model: null # ${model.hidden_size}
      # warmup_steps: null # use to set warmup_steps explicitly or leave as null to calculate
      # warmup_ratio: null # calculate warmup_steps from warmup_ratio * max_steps, but will throw error if max_steps * warmup_ratio < 1
      # max_steps: ${trainer.max_steps} # can also use ${trainer.max_steps} to scale
      # min_lr: 1e-8

  train_ds:
    num_batches: null
    pin_memory: ${data.pin_memory}
    seed: ${seed}
    no_torsion: ${model.diffusion.no_torsion}
    all_atoms: ${data.all_atoms}
    data_dir: ${data.data_dir}
    limit_complexes: ${data.limit_complexes}
    receptor_radius: ${data.receptor_radius}
    c_alpha_max_neighbors: ${data.c_alpha_max_neighbors}
    remove_hs: ${data.remove_hs}
    max_lig_size: ${data.max_lig_size}
    matching_popsize: ${data.matching_popsize}
    matching_maxiter: ${data.matching_maxiter}
    num_workers: ${data.num_workers}
    atom_radius: ${data.atom_radius}
    atom_max_neighbors: ${data.atom_max_neighbors}
    esm_embeddings_path: ${data.esm_embeddings_path}
    cache_path: ${data.cache_path}
    num_conformers: ${data.num_conformers}
    split_train: ${data.split_train}
    chunk_size: ${data.chunk_size}

  validation_ds:
    num_batches: null
    pin_memory: ${data.pin_memory}
    seed: ${seed}
    no_torsion: ${model.diffusion.no_torsion}
    all_atoms: ${data.all_atoms}
    data_dir: ${data.data_dir}
    limit_complexes: ${data.limit_complexes}
    receptor_radius: ${data.receptor_radius}
    c_alpha_max_neighbors: ${data.c_alpha_max_neighbors}
    remove_hs: ${data.remove_hs}
    max_lig_size: ${data.max_lig_size}
    matching_popsize: ${data.matching_popsize}
    matching_maxiter: ${data.matching_maxiter}
    num_workers: ${data.num_workers}
    atom_radius: ${data.atom_radius}
    atom_max_neighbors: ${data.atom_max_neighbors}
    esm_embeddings_path: ${data.esm_embeddings_path}
    cache_path: ${data.cache_path}
    num_conformers: ${data.num_conformers}
    split_val: ${data.split_val}
    chunk_size: ${data.chunk_size}

  test_ds:
    num_batches: null # ${model.num_batches}
    pin_memory: ${data.pin_memory}
    seed: ${seed}
    no_torsion: ${model.diffusion.no_torsion}
    all_atoms: ${data.all_atoms}
    data_dir: ${data.data_dir}
    limit_complexes: ${data.limit_complexes}
    receptor_radius: ${data.receptor_radius}
    c_alpha_max_neighbors: ${data.c_alpha_max_neighbors}
    remove_hs: ${data.remove_hs}
    max_lig_size: ${data.max_lig_size}
    matching_popsize: ${data.matching_popsize}
    matching_maxiter: ${data.matching_maxiter}
    num_workers: ${data.num_workers}
    atom_radius: ${data.atom_radius}
    atom_max_neighbors: ${data.atom_max_neighbors}
    esm_embeddings_path: ${data.esm_embeddings_path}
    cache_path: ${data.cache_path}
    num_conformers: ${data.num_conformers}
    split_test: ${data.split_test}
    chunk_size: ${data.chunk_size}


exp_manager:
  name: ${name}
  # checkpoint reloading and saving
  resume_if_exists: True # autmatically resume if checkpoint exists
  resume_ignore_no_checkpoint: True # leave as True, will start new training if resume_if_exists is True but no checkpoint exists
  create_checkpoint_callback: True # leave as True, use exp_manger for checkpoints
  checkpoint_callback_params:
    save_top_k: 1 # number of checkpoints to save
    monitor: ${model.inference_earlystop_metric} # use loss to select best checkpoints
    mode: ${model.inference_earlystop_goal} # use min or max of monitored metric to select best checkpoints
    save_last: True # always save last checkpoint
    always_save_nemo: True # not implemented for model parallel, additionally save NeMo-style checkpoint during validation, set to False if checkpoint saving is time consuming
    filename: '${name}-{valinf_rmsds_lt2:.4f}-{val_loss:.4f}-{train_loss:.4f}-{step}' # -{consumed_samples}'
  # EMA
  ema: # Exponential Moving Average; is picked up by exp_manager()
    enable: True # Creates EMA callback in exp_manager
    decay: 0.999 # (ema_rate) The exponential decay used when calculating the moving average. Has to be between 0-1.
    cpu_offload: False  # If EMA parameters should be offloaded to CPU to save GPU memory
    every_n_steps: 1 # Apply EMA every n global steps
    validate_original_weights: False # Validate the EMA weights instead of the original weights. Note this means that when saving the model, the validation metrics are calculated with the EMA weights.
  # logging
  exp_dir: ${oc.env:BIONEMO_HOME}/results/nemo_experiments/${.name}/${.wandb_logger_kwargs.name}
  explicit_log_dir: ${.exp_dir}
  create_wandb_logger: False
  create_tensorboard_logger: False
  wandb_logger_kwargs:
    project: diffdock_large_score_model
    name: ${model.name}_training
    group: ${model.name}
    job_type: Localhost_nodes_${trainer.num_nodes}_gpus_${trainer.devices}
    notes: "date: ${now:%y%m%d-%H%M%S}"
    tags:
      - ${name}
      - ${model.name}
    offline: False # set to True if there are issues uploading to WandB during training


nsys_profile:
  enabled: False
  start_step: 0  # Global batch to start profiling
  end_step: 0 # Global batch to end profiling
  ranks: [0] # Global rank IDs to profile
  gen_shape: False # Generate model and kernel details including input shapes
# And then wrap the model training script with:
# nsys profile -s none -o <profile filepath>  -t cuda,nvtx --force-overwrite true --capture-range=cudaProfilerApi --capture-range-end=stop python ./examples/...
# See more options at: https://docs.nvidia.com/nsight-systems/UserGuide/index.html#cli-profiling
