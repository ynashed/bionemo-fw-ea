{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b43cec",
   "metadata": {},
   "source": [
    "# Inference Sample\n",
    "\n",
    "Copyright (c) 2022, NVIDIA CORPORATION. Licensed under the Apache License, Version 2.0 (the \"License\") you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0 \n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "### Prerequisite\n",
    "* Linux OS\n",
    "* Pascal, Volta, Turing, or an NVIDIA Ampere architecture-based GPU.\n",
    "* NVIDIA Driver\n",
    "* Docker\n",
    "\n",
    "### Import\n",
    "Components for inferencing are part of the BioNeMo MegaMolBART source code. This notebook demonstrates the use of these components.\n",
    "\n",
    "MegaMolBARTInferer implements following functions:\n",
    "* `seqs_to_hidden`\n",
    "* `seqs_to_embedding`\n",
    "* `hidden_to_seqs`\n",
    "\n",
    "Note that gRPC limits request size to 4MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from bionemo.triton.inference_wrapper import new_inference_wrapper\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38725cbe",
   "metadata": {},
   "source": [
    "### Setup and Test Data\n",
    "\n",
    "`new_inference_wrapper` creates a client that communicates with the Triton model server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d59f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = new_inference_wrapper(\"grpc://localhost:8001\")\n",
    "\n",
    "smis = [\n",
    "    'c1ccc2ccccc2c1',\n",
    "    'COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbd797",
   "metadata": {},
   "source": [
    "### SMILES to hidden state\n",
    "\n",
    "`seqs_to_hidden` queries the model to fetch the latent space representation of the SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9160856",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, pad_masks = connection.seqs_to_hidden(smis)\n",
    "print(f\"{hidden_states.shape=}\")\n",
    "print(f\"{pad_masks.shape=}\")\n",
    "\n",
    "assert tuple(hidden_states.shape) == (2, 45, 512)\n",
    "assert tuple(pad_masks.shape) == (2, 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden States to Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = connection.hiddens_to_embedding(hidden_states, pad_masks)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embeddings.shape) == (2, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f5a9d",
   "metadata": {},
   "source": [
    "### SMILES to Embedding\n",
    "\n",
    "`seqs_to_embedding` queries the model to fetch the encoder embedding for the input SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = connection.seqs_to_embedding(smis)\n",
    "print(f\"{embedding.shape=}\")\n",
    "assert tuple(embedding.shape) == (2, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7862d9b",
   "metadata": {},
   "source": [
    "### Hidden state to SMILES\n",
    "\n",
    "`hidden_to_seqs` decodes the latent space representation back to SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04df8c33352e823",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def canonicalize_smiles(smiles: str) -> str:\n",
    "    \"\"\"Canonicalize input SMILES\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    canon_smiles = Chem.MolToSmiles(mol, canonical=True)\n",
    "    return canon_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "infered_smis = connection.hidden_to_seqs(hidden_states, pad_masks)\n",
    "canon_infered_smis = list(map(canonicalize_smiles, infered_smis))\n",
    "print(f\"Reconstructed SMILES:\\n{canon_infered_smis}\")\n",
    "assert len(canon_infered_smis) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f3876bc49184c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Sampling: Generate SMILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63c2b011a90b86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = connection.sample_seqs(smis)\n",
    "print(f\"Generated {len(samples)} samples\")\n",
    "assert len(samples) == 2\n",
    "for i,s in enumerate(samples):\n",
    "    print(f\"Sample #{i+1} (length: {len(s)}):\\n{s}\\n-----------------------\")\n",
    "    assert len(s) == 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
