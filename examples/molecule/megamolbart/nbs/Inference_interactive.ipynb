{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b43cec",
   "metadata": {},
   "source": [
    "# Inference Sample\n",
    "\n",
    "SPDX-FileCopyrightText: Copyright (c) <year> NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "SPDX-License-Identifier: LicenseRef-NvidiaProprietary\n",
    "\n",
    "NVIDIA CORPORATION, its affiliates and licensors retain all intellectual property and proprietary rights in and to this material, related documentation and any modifications thereto. Any use, reproduction, disclosure or distribution of this material and related documentation without an express license agreement from NVIDIA CORPORATION or its affiliates is strictly prohibited.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "**Before diving in, ensure you have all [necessary prerequisites](https://docs.nvidia.com/bionemo-framework/latest/pre-reqs.html). If this is your first time using BioNeMo, we recommend following the [quickstart guide](https://docs.nvidia.com/bionemo-framework/latest/quickstart-fw.html) first.** \n",
    "\n",
    "Additionally, this notebook assumes you have started a [local inference server](https://docs.nvidia.com/bionemo-framework/latest/inference-triton-fw.html) using a pretrained [MegaMolBART](https://docs.nvidia.com/bionemo-framework/latest/models/megamolbart.html) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca44898eb4ca64",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "try:\n",
    "    BIONEMO_HOME: Path = Path(os.environ['BIONEMO_HOME']).absolute()\n",
    "except KeyError:\n",
    "    print(\"Must have BIONEMO_HOME set in the environment! See docs for instructions.\")\n",
    "    raise\n",
    "\n",
    "config_path = BIONEMO_HOME / \"examples\" / \"molecule\" / \"megamolbart\" / \"conf\"\n",
    "print(f\"Using model configuration at: {config_path}\")\n",
    "assert config_path.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38725cbe",
   "metadata": {},
   "source": [
    "### Setup and Test Data\n",
    "\n",
    "`InferenceWrapper` is an adaptor that allows interaction with inference service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d59f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smis = [\n",
    "    'c1ccc2ccccc2c1',\n",
    "    'COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bionemo.triton.utils import load_model_config\n",
    "\n",
    "cfg = load_model_config(config_path, config_name=\"infer.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f30d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bionemo.triton.utils import load_model_for_inference\n",
    "from bionemo.model.molecule.megamolbart.infer import MegaMolBARTInference\n",
    "\n",
    "inferer = load_model_for_inference(cfg, interactive=True)\n",
    "\n",
    "print(f\"Loaded a {type(inferer)}\")\n",
    "assert isinstance(inferer, MegaMolBARTInference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbd797",
   "metadata": {},
   "source": [
    "### SMILES to hidden state\n",
    "\n",
    "`seq_to_hiddens` obtains the model's latent space representation of the SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9160856",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, pad_masks = inferer.seq_to_hiddens(smis)\n",
    "print(f\"{hidden_states.shape=}\")\n",
    "print(f\"{pad_masks.shape=}\")\n",
    "\n",
    "assert tuple(hidden_states.shape) == (2, 45, 512)\n",
    "assert tuple(pad_masks.shape) == (2, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d12172",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = inferer.hiddens_to_embedding(hidden_states, pad_masks)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embeddings.shape) == (2, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f5a9d",
   "metadata": {},
   "source": [
    "### SMILES to Embedding\n",
    "\n",
    "`smis_to_embedding` queries the model to fetch the encoder embedding for the input SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = inferer.seq_to_embeddings(smis)\n",
    "print(f\"{embedding.shape=}\")\n",
    "assert tuple(embedding.shape) == (2, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c94349146c772f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that this is equivalent to first producing the hidden representation, then using the input mask to produce embeddings with the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7862d9b",
   "metadata": {},
   "source": [
    "### Hidden state to SMILES\n",
    "\n",
    "`hidden_to_smis` decodes the latent space representation back to SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "def canonicalize_smiles(smiles: str) -> str:\n",
    "    \"\"\"Canonicalize input SMILES\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    canon_smiles = Chem.MolToSmiles(mol, canonical=True)\n",
    "    return canon_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82275a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "infered_smis = inferer.hiddens_to_seq(hidden_states, pad_masks)\n",
    "canon_infered_smis = list(map(canonicalize_smiles, infered_smis))\n",
    "print(f\"Reconstructed SMILES:\\n{canon_infered_smis}\")\n",
    "assert len(canon_infered_smis) == 2\n",
    "for i, (original, reconstructed) in enumerate(zip(smis, canon_infered_smis)):\n",
    "    assert original == reconstructed, f\"Failure to recongstruct on #{i+1}: {original=}, {reconstructed=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed81414",
   "metadata": {},
   "source": [
    "### Sampling: Generate SMILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = inferer.sample(num_samples=3, return_embedding=False, sampling_method=\"greedy-perturbate\", seqs=smis)\n",
    "print(f\"Generated {len(samples)} samples\")\n",
    "\n",
    "assert len(samples) == 2\n",
    "for i,s in enumerate(samples):\n",
    "    print(f\"Sample #{i+1} (length: {len(s)}):\\n{s}\\n-----------------------\")\n",
    "    assert len(s) == 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
