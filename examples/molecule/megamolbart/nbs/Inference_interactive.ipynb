{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b43cec",
   "metadata": {},
   "source": [
    "# Inference Sample\n",
    "\n",
    "Copyright (c) 2022, NVIDIA CORPORATION. Licensed under the Apache License, Version 2.0 (the \"License\") you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0 \n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "### Prerequisite\n",
    "* Linux OS\n",
    "* Pascal, Volta, Turing, or an NVIDIA Ampere architecture-based GPU.\n",
    "* NVIDIA Driver\n",
    "* Docker\n",
    "\n",
    "### Import\n",
    "Components for inferencing are part of the BioNeMo MegaMolBART source code. This notebook demonstrates the use of these components.\n",
    "\n",
    "MegaMolBARTInferer implements following functions:\n",
    "* `smis_to_hidden`\n",
    "* `smis_to_embedding`\n",
    "* `hidden_to_smis`\n",
    "\n",
    "Note that gRPC limits request size to 4MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca44898eb4ca64",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "try:\n",
    "    BIONEMO_HOME: Path = Path(os.environ['BIONEMO_HOME']).absolute()\n",
    "except KeyError:\n",
    "    print(\"Must have BIONEMO_HOME set in the environment! See docs for instructions.\")\n",
    "    raise\n",
    "\n",
    "config_path = BIONEMO_HOME / \"examples\" / \"molecule\" / \"megamolbart\" / \"conf\"\n",
    "print(f\"Using model configuration at: {config_path}\")\n",
    "assert config_path.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38725cbe",
   "metadata": {},
   "source": [
    "### Setup and Test Data\n",
    "\n",
    "`InferenceWrapper` is an adaptor that allows interaction with inference service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d59f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smis = [\n",
    "    'c1ccc2ccccc2c1',\n",
    "    'COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bionemo.triton.utils import load_model_config\n",
    "\n",
    "cfg = load_model_config(config_path, config_name=\"infer.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f30d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bionemo.triton.utils import load_model_for_inference\n",
    "from bionemo.model.molecule.megamolbart.infer import MegaMolBARTInference\n",
    "\n",
    "inferer = load_model_for_inference(cfg, interactive=True)\n",
    "\n",
    "print(f\"Loaded a {type(inferer)}\")\n",
    "assert isinstance(inferer, MegaMolBARTInference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbd797",
   "metadata": {},
   "source": [
    "### SMILES to hidden state\n",
    "\n",
    "`seq_to_hiddens` obtains the model's latent space representation of the SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9160856",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, pad_masks = inferer.seq_to_hiddens(smis)\n",
    "print(f\"{hidden_states.shape=}\")\n",
    "print(f\"{pad_masks.shape=}\")\n",
    "\n",
    "assert tuple(hidden_states.shape) == (2, 45, 512)\n",
    "assert tuple(pad_masks.shape) == (2, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d12172",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = inferer.hiddens_to_embedding(hidden_states, pad_masks)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embeddings.shape) == (2, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f5a9d",
   "metadata": {},
   "source": [
    "### SMILES to Embedding\n",
    "\n",
    "`smis_to_embedding` queries the model to fetch the encoder embedding for the input SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = inferer.seq_to_embeddings(smis)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embedding.shape) == (2, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c94349146c772f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that this is equivalent to first producing the hidden representation, then using the input mask to produce embeddings with the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7862d9b",
   "metadata": {},
   "source": [
    "### Hidden state to SMILES\n",
    "\n",
    "`hidden_to_smis` decodes the latent space representation back to SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "def canonicalize_smiles(smiles: str) -> str:\n",
    "    \"\"\"Canonicalize input SMILES\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    canon_smiles = Chem.MolToSmiles(mol, canonical=True)\n",
    "    return canon_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82275a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "infered_smis = inferer.hiddens_to_seq(hidden_states, pad_masks)\n",
    "canon_infered_smis = list(map(canonicalize_smiles, infered_smis))\n",
    "print(f\"Reconstructed SMILES:\\n{canon_infered_smis}\")\n",
    "assert len(canon_infered_smis) == 2\n",
    "for i, (original, reconstructed) in enumerate(zip(smis, canon_infered_smis)):\n",
    "    assert original == reconstructed, f\"Failure to recongstruct on #{i+1}: {original=}, {reconstructed=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed81414",
   "metadata": {},
   "source": [
    "### Sampling: Generate SMILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(smile: str) -> List[str]:\n",
    "    return inferer.sample(num_samples=10, return_embedding=False, sampling_method=\"greedy-perturbate\", smis=[smile])\n",
    "\n",
    "samples = [sample(smile) for smile in smis]\n",
    "print(f\"Generated {len(samples)} samples\")\n",
    "\n",
    "assert len(samples) == 2\n",
    "for i,s in enumerate(samples):\n",
    "    print(f\"Sample #{i+1} (length: {len(s)}):\\n{s}\\n-----------------------\")\n",
    "    assert len(s) == 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
